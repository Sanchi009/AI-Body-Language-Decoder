# AI-Body-Language-Decoder

Unveil the Unspoken: An AI-powered Body Language Decoder leveraging Mediapipe and Machine Learning.

## Introduction

This project demonstrates how to build an AI body language decoder using Mediapipe to estimate facial and body landmarks. By collecting and processing joint coordinates, and training a custom pose classification model, we can decode a person's body language in real-time.

## Features

- Utilizes Mediapipe to estimate facial and body landmarks.
- Collects and processes joint coordinates using Pandas.
- Trains a custom pose classification model using Scikit-Learn.
- Decodes body language in real-time, identifying emotions like happiness, sadness, victory, sleepiness, etc.

## Results 
  

## Installation

1. Install the required packages:

   ```bash
   pip install mediapipe opencv-python pandas scikit-learn
   
2. Clone this repository:
   
   ```bash
    git clone https://github.com/your-username/AI-Body-Language-Decoder.git
    cd ai-body-language-decoder

